{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio_4_ID_MAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKa0kAP2rnfQ"
      },
      "source": [
        "## **Introducción:**\n",
        "\n",
        "En este punto, usaremos el problema de predicción utilizando la base de datos \"**Open Problems– Single-Cell Perturbations**\", la cual contiene datos experimentales sobre perturbaciones en células individuales. Para ello, utilizaremos técnicas de machine learning, incluyendo K-NN (lineal regresion) y regresión lineal, con el fin de identificar el modelo que mejor se ajuste a los datos.\n",
        "\n",
        "Finalmente, evaluaremos el desempeño de los modelos construidos mediante la creación de una tabla de error que incluirá las métricas más relevantes en problemas de regresión: MAPE, MAE, RMSE, MSE y R². Esta tabla nos permitirá comparar la eficacia de los modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YOXUp1BkndB"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q9os4Qm2knCf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_squared_error,make_scorer, mean_absolute_percentage_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZcE-gfdkrxk"
      },
      "source": [
        "# Base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lXrVH2LsFY9"
      },
      "source": [
        "En esta sección, cargamos la base de datos que utilizaremos para nuestros modelos: K-NN (lineal regresion) y regresión lineal. Es importante tener en cuenta que el análisis descriptivo de esta variable se encuentra desarrollado en el punto 2, inciso 2, del examen práctico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7Qpv0pmptv5B"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"# Ruta del archivo Parquet\\nfile_path = 'https://drive.google.com/uc?export=download&id=1Jwi-8080GYIStM3Wp6AyVQ-KmQsXr0YO'\\ndf_parqdtra = pd.read_parquet(file_path, engine='pyarrow')\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# Ruta del archivo Parquet\n",
        "file_path = 'https://drive.google.com/uc?export=download&id=1Jwi-8080GYIStM3Wp6AyVQ-KmQsXr0YO'\n",
        "df_parqdtra = pd.read_parquet(file_path, engine='pyarrow')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAtxpw90io1a",
        "outputId": "7a4bbf65-16a0-4170-d3eb-2997a1e9b05a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'print(df_parqdtra.head())\\nprint(df_parqdtra.size)'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''print(df_parqdtra.head())\n",
        "print(df_parqdtra.size)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "            cell_type             sm_name sm_lincs_id  \\\n",
        "0            NK cells        Clotrimazole    LSM-5341   \n",
        "1        T cells CD4+        Clotrimazole    LSM-5341   \n",
        "2        T cells CD8+        Clotrimazole    LSM-5341   \n",
        "3  T regulatory cells        Clotrimazole    LSM-5341   \n",
        "4            NK cells  Mometasone Furoate    LSM-3349   \n",
        "\n",
        "                                              SMILES  control      A1BG  \\\n",
        "0             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.104720   \n",
        "1             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.915953   \n",
        "2             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False -0.387721   \n",
        "3             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.232893   \n",
        "4  C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...    False  4.290652   \n",
        "\n",
        "   A1BG-AS1       A2M   A2M-AS1     A2MP1  ...      ZUP1      ZW10    ZWILCH  \\\n",
        "0 -0.077524 -1.625596 -0.144545  0.143555  ... -0.227781 -0.010752 -0.023881   \n",
        "1 -0.884380  0.371834 -0.081677 -0.498266  ... -0.494985 -0.303419  0.304955   \n",
        "2 -0.305378  0.567777  0.303895 -0.022653  ... -0.119422 -0.033608 -0.153123   \n",
        "3  0.129029  0.336897  0.486946  0.767661  ...  0.451679  0.704643  0.015468   \n",
        "4 -0.063864 -0.017443 -0.541154  0.570982  ...  0.758474  0.510762  0.607401   \n",
        "\n",
        "      ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1  \n",
        "0  0.674536 -0.453068  0.005164 -0.094959  0.034127  0.221377  0.368755  \n",
        "1 -0.333905 -0.315516 -0.369626 -0.095079  0.704780  1.096702 -0.869887  \n",
        "2  0.183597 -0.555678 -1.494789 -0.213550  0.415768  0.078439 -0.259365  \n",
        "...\n",
        "4 -0.123059  0.214366  0.487838 -0.819775  0.112365 -0.122193  0.676629  \n",
        "\n",
        "[5 rows x 18216 columns]\n",
        "11184624\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oesrs0seLFq"
      },
      "source": [
        "# Pipeline y Gridsearchcv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW4a0-6Oo519",
        "outputId": "2e21a566-950e-4b4b-bfb7-92bef137ae01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"import pandas as pd\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n# Crea una copia del DataFrame original\\ndf_parqdtra_copy = df_parqdtra.copy()\\n\\n# Aplicar One-Hot Encoding a 'cell_type' y 'sm_name'\\nencoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' evita la multicolinealidad\\nencoded_features = encoder.fit_transform(df_parqdtra_copy[['cell_type', 'sm_name']])\\n\\n# Crear un DataFrame con las columnas codificadas\\ndf_encoded = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['cell_type', 'sm_name']))\\n\\n# Concatenar las columnas codificadas con el resto del DataFrame (excluyendo 'cell_type' y 'sm_name')\\ndf_parqdtra_encoded = pd.concat([df_parqdtra_copy.drop(columns=['cell_type', 'sm_name']), df_encoded], axis=1)\\n\\nX = df_encoded\\n# Las columnas de genes\\ny = df_parqdtra_encoded[df_parqdtra.columns[4:]]\\n\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Crea una copia del DataFrame original\n",
        "df_parqdtra_copy = df_parqdtra.copy()\n",
        "\n",
        "# Aplicar One-Hot Encoding a 'cell_type' y 'sm_name'\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' evita la multicolinealidad\n",
        "encoded_features = encoder.fit_transform(df_parqdtra_copy[['cell_type', 'sm_name']])\n",
        "\n",
        "# Crear un DataFrame con las columnas codificadas\n",
        "df_encoded = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['cell_type', 'sm_name']))\n",
        "\n",
        "# Concatenar las columnas codificadas con el resto del DataFrame (excluyendo 'cell_type' y 'sm_name')\n",
        "df_parqdtra_encoded = pd.concat([df_parqdtra_copy.drop(columns=['cell_type', 'sm_name']), df_encoded], axis=1)\n",
        "\n",
        "X = df_encoded\n",
        "# Las columnas de genes\n",
        "y = df_parqdtra_encoded[df_parqdtra.columns[4:]]\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyE05z1OsI8T"
      },
      "source": [
        "Aca se toman los datos para el modelo de machine learning. Aplica One-Hot Encoding a las columnas categóricas 'cell_type' y 'sm_name', convirtiéndolas en variables numéricas, y luego las combina con el resto del DataFrame. Finalmente, coge estas columnas para las variables predictoras (X) y las columnas de genes como variables objetivo (y)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6IEHuTXk5B0"
      },
      "source": [
        "### Dividir el conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmx7QxDwvqGo"
      },
      "source": [
        "**se divide asi:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ZfbO92vpxR",
        "outputId": "8c21a7f9-2fa6-4786-d071-b598d9e557ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'print(X.head())\\nprint(\"-------------------------------\")\\nprint(y.head())'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''print(X.head())\n",
        "print(\"-------------------------------\")\n",
        "print(y.head())'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "            cell_type             sm_name sm_lincs_id  \\\n",
        "0            NK cells        Clotrimazole    LSM-5341   \n",
        "1        T cells CD4+        Clotrimazole    LSM-5341   \n",
        "2        T cells CD8+        Clotrimazole    LSM-5341   \n",
        "3  T regulatory cells        Clotrimazole    LSM-5341   \n",
        "4            NK cells  Mometasone Furoate    LSM-3349   \n",
        "\n",
        "                                              SMILES  control      A1BG  \\\n",
        "0             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.104720   \n",
        "1             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.915953   \n",
        "2             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False -0.387721   \n",
        "3             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1    False  0.232893   \n",
        "4  C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...    False  4.290652   \n",
        "\n",
        "   A1BG-AS1       A2M   A2M-AS1     A2MP1  ...      ZUP1      ZW10    ZWILCH  \\\n",
        "0 -0.077524 -1.625596 -0.144545  0.143555  ... -0.227781 -0.010752 -0.023881   \n",
        "1 -0.884380  0.371834 -0.081677 -0.498266  ... -0.494985 -0.303419  0.304955   \n",
        "2 -0.305378  0.567777  0.303895 -0.022653  ... -0.119422 -0.033608 -0.153123   \n",
        "3  0.129029  0.336897  0.486946  0.767661  ...  0.451679  0.704643  0.015468   \n",
        "4 -0.063864 -0.017443 -0.541154  0.570982  ...  0.758474  0.510762  0.607401   \n",
        "\n",
        "      ZWINT      ZXDA      ZXDB      ZXDC    ZYG11B       ZYX     ZZEF1  \n",
        "0  0.674536 -0.453068  0.005164 -0.094959  0.034127  0.221377  0.368755  \n",
        "1 -0.333905 -0.315516 -0.369626 -0.095079  0.704780  1.096702 -0.869887  \n",
        "2  0.183597 -0.555678 -1.494789 -0.213550  0.415768  0.078439 -0.259365  \n",
        "...\n",
        "4 -0.123059  0.214366  0.487838 -0.819775  0.112365 -0.122193  0.676629  \n",
        "\n",
        "[5 rows x 18216 columns]\n",
        "11184624\n",
        "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
        "  warnings.warn(\n",
        "   cell_type_Myeloid cells  cell_type_NK cells  cell_type_T cells CD4+  \\\n",
        "0                      0.0                 1.0                     0.0   \n",
        "1                      0.0                 0.0                     1.0   \n",
        "2                      0.0                 0.0                     0.0   \n",
        "3                      0.0                 0.0                     0.0   \n",
        "4                      0.0                 1.0                     0.0   \n",
        "\n",
        "   cell_type_T cells CD8+  cell_type_T regulatory cells  \\\n",
        "0                     0.0                           0.0   \n",
        "1                     0.0                           0.0   \n",
        "2                     1.0                           0.0   \n",
        "3                     0.0                           1.0   \n",
        "4                     0.0                           0.0   \n",
        "\n",
        "   sm_name_ABT-199 (GDC-0199)  sm_name_ABT737  \\\n",
        "0                         0.0             0.0   \n",
        "1                         0.0             0.0   \n",
        "2                         0.0             0.0   \n",
        "3                         0.0             0.0   \n",
        "4                         0.0             0.0   \n",
        "\n",
        "   sm_name_AMD-070 (hydrochloride)  sm_name_AT 7867  sm_name_AT13387  ...  \\\n",
        "0                              0.0              0.0              0.0  ...   \n",
        "1                              0.0              0.0              0.0  ...   \n",
        "2                              0.0              0.0              0.0  ...   \n",
        "...\n",
        "3  0.865027  0.189114  0.224700 -0.048233  0.216139 -0.085024  \n",
        "4  0.214366  0.487838 -0.819775  0.112365 -0.122193  0.676629  \n",
        "\n",
        "[5 rows x 18212 columns]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWZCZQBhscAW"
      },
      "source": [
        "\n",
        "**Análisis de Tablas:**\n",
        "\n",
        "Aquí observamos cómo quedaron los DataFrames que vamos a utilizar en nuestro modelo. Además, se muestra cómo quedaron las variables `sm_names` y `cell_type`. Esto se hizo para poder realizar los modelos solicitados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT9RL4OXsMKR"
      },
      "source": [
        "Utilicé la métrica **Mean Rowwise Root Mean Squared Error (MRRMSE)** para la evaluación y validación del modelo, ya que permite capturar el error promedio de manera más precisa a nivel de filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2iRBvnR3wShK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def MRRMSE(y_real, y_pred):\\n    rowwise_rmse = np.sqrt(np.mean((y_real - y_pred) ** 2, axis=1))\\n    return np.mean(rowwise_rmse)'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''def MRRMSE(y_real, y_pred):\n",
        "    rowwise_rmse = np.sqrt(np.mean((y_real - y_pred) ** 2, axis=1))\n",
        "    return np.mean(rowwise_rmse)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK_i_j1qd3bL",
        "outputId": "66fa9a9a-d74c-46ae-f7b4-077ebecd6d9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\\nresul = make_scorer(MRRMSE, greater_is_better = False)\\nprint(\"Size of training set: {} size of validation set: {} size of test set: {}\\n\".\\n      format(X_train.shape[0], X_test.shape[0], X_test.shape[0]))'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "resul = make_scorer(MRRMSE, greater_is_better = False)\n",
        "print(\"Size of training set: {} size of validation set: {} size of test set: {}\\n\".\n",
        "      format(X_train.shape[0], X_test.shape[0], X_test.shape[0]))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Size of training set: 491 size of validation set: 123 size of test set: 123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUAjNJJ_eY0r",
        "outputId": "9c884817-4eea-47c8-a97c-480d022c0bf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'print(X_test.head())\\nprint(\"------------------------------\")\\nprint(y_test.head())'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''print(X_test.head())\n",
        "print(\"------------------------------\")\n",
        "print(y_test.head())'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "    cell_type_Myeloid cells  cell_type_NK cells  cell_type_T cells CD4+  \\\n",
        "533                      0.0                 0.0                     0.0   \n",
        "544                      0.0                 1.0                     0.0   \n",
        "41                       0.0                 0.0                     1.0   \n",
        "148                      0.0                 0.0                     0.0   \n",
        "111                      0.0                 0.0                     1.0   \n",
        "\n",
        "     cell_type_T cells CD8+  cell_type_T regulatory cells  \\\n",
        "533                     1.0                           0.0   \n",
        "544                     0.0                           0.0   \n",
        "41                      0.0                           0.0   \n",
        "148                     1.0                           0.0   \n",
        "111                     0.0                           0.0   \n",
        "\n",
        "     sm_name_ABT-199 (GDC-0199)  sm_name_ABT737  \\\n",
        "533                         0.0             0.0   \n",
        "544                         0.0             0.0   \n",
        "41                          0.0             0.0   \n",
        "148                         0.0             0.0   \n",
        "111                         0.0             0.0   \n",
        "\n",
        "     sm_name_AMD-070 (hydrochloride)  sm_name_AT 7867  sm_name_AT13387  ...  \\\n",
        "533                              0.0              0.0              0.0  ...   \n",
        "544                              0.0              0.0              0.0  ...   \n",
        "41                               0.0              0.0              0.0  ...   \n",
        "...\n",
        "148  0.394251  0.522069  0.251634  0.000173 -0.190295  1.289288  0.388646  \n",
        "111  0.173986  1.400341  1.571638 -0.242477 -2.021973 -4.161092  0.953246  \n",
        "\n",
        "[5 rows x 18212 columns]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfBqyTKeSf-",
        "outputId": "1bceda1f-893a-4d2d-846a-ef0090a95049"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'print(X_train.head())\\nprint(\"------------------------------\")\\nprint(y_train.head())'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''print(X_train.head())\n",
        "print(\"------------------------------\")\n",
        "print(y_train.head())'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "     cell_type_Myeloid cells  cell_type_NK cells  cell_type_T cells CD4+  \\\n",
        "291                      0.0                 0.0                     0.0   \n",
        "507                      0.0                 0.0                     0.0   \n",
        "328                      0.0                 0.0                     1.0   \n",
        "609                      0.0                 0.0                     0.0   \n",
        "69                       0.0                 0.0                     1.0   \n",
        "\n",
        "     cell_type_T cells CD8+  cell_type_T regulatory cells  \\\n",
        "291                     1.0                           0.0   \n",
        "507                     1.0                           0.0   \n",
        "328                     0.0                           0.0   \n",
        "609                     0.0                           1.0   \n",
        "69                      0.0                           0.0   \n",
        "\n",
        "     sm_name_ABT-199 (GDC-0199)  sm_name_ABT737  \\\n",
        "291                         0.0             0.0   \n",
        "507                         0.0             0.0   \n",
        "328                         0.0             0.0   \n",
        "609                         0.0             0.0   \n",
        "69                          0.0             0.0   \n",
        "\n",
        "     sm_name_AMD-070 (hydrochloride)  sm_name_AT 7867  sm_name_AT13387  ...  \\\n",
        "291                              0.0              0.0              0.0  ...   \n",
        "507                              0.0              0.0              0.0  ...   \n",
        "328                              0.0              0.0              0.0  ...   \n",
        "...\n",
        "609  1.073983  0.356939 -0.029603 -0.528817  0.105138  0.491015 -0.979951  \n",
        "69   0.192888  0.179910  0.143050  0.220797 -0.881506 -1.374488 -0.258518  \n",
        "\n",
        "[5 rows x 18212 columns]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11MIL2UPsSO0"
      },
      "source": [
        "En estas tablas se observa los datos utilizados para el modelo. Los datos se dividen en conjuntos de entrenamiento y prueba, denominados `X_train`, `X_test`, `y_train`, y `y_test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SciIK2kWk-bm"
      },
      "source": [
        "# Modelo de regresion KNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgCvNryNhZv6",
        "outputId": "321b354c-b450-49fa-cc97-2f7d5cdff378"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\npipeline_kr = Pipeline([\\n    (\\'scaler\\', StandardScaler()),\\n    (\\'regressor\\', KNeighborsRegressor())\\n])\\nparam_grid_kr = {\\n    \\'regressor__n_neighbors\\': [5, 10],\\n    \\'regressor__weights\\': [\\'uniform\\', \\'distance\\']\\n}\\n\\n# Configurar validación cruzada\\nkfo = KFold(n_splits=3, shuffle=True, random_state=42)\\n\\n# Crear el scorer utilizando la métrica Mean Rowwise Root Mean Squared Error (MRRMSE)\\ndef MRRMSE(y_real, y_pred):\\n    rowwise_rmse = np.sqrt(np.mean((y_real - y_pred) ** 2, axis=1))\\n    return np.mean(rowwise_rmse)\\n\\nresul = make_scorer(MRRMSE, greater_is_better=False)\\n\\n# Inicializar GridSearchCV\\ngrid_knr = GridSearchCV(pipeline_kr, param_grid_kr, cv=kfo, scoring=resul, n_jobs=-1)\\n\\ntry:\\n    # Ajustar el modelo\\n    grid_knr.fit(X_train, y_train)\\nexcept KeyboardInterrupt:\\n    print(\"Interrupción manual del proceso.\")\\n\\n# Realizar predicciones y mostrar los resultados\\nknn_y_pred = grid_knr.predict(X_test)\\nprint(f\\'Best parameters: {grid_knr.best_params_}\\')\\nprint(f\\'MRRMSE en el conjunto de prueba: {MRRMSE(y_test, knn_y_pred)}\\')\\n'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "pipeline_kr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', KNeighborsRegressor())\n",
        "])\n",
        "param_grid_kr = {\n",
        "    'regressor__n_neighbors': [5, 10],\n",
        "    'regressor__weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# Configurar validación cruzada\n",
        "kfo = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Crear el scorer utilizando la métrica Mean Rowwise Root Mean Squared Error (MRRMSE)\n",
        "def MRRMSE(y_real, y_pred):\n",
        "    rowwise_rmse = np.sqrt(np.mean((y_real - y_pred) ** 2, axis=1))\n",
        "    return np.mean(rowwise_rmse)\n",
        "\n",
        "resul = make_scorer(MRRMSE, greater_is_better=False)\n",
        "\n",
        "# Inicializar GridSearchCV\n",
        "grid_knr = GridSearchCV(pipeline_kr, param_grid_kr, cv=kfo, scoring=resul, n_jobs=-1)\n",
        "\n",
        "try:\n",
        "    # Ajustar el modelo\n",
        "    grid_knr.fit(X_train, y_train)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Interrupción manual del proceso.\")\n",
        "\n",
        "# Realizar predicciones y mostrar los resultados\n",
        "knn_y_pred = grid_knr.predict(X_test)\n",
        "print(f'Best parameters: {grid_knr.best_params_}')\n",
        "print(f'MRRMSE en el conjunto de prueba: {MRRMSE(y_test, knn_y_pred)}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjkJhsEOlNz6"
      },
      "source": [
        "## LOS RESULTADOS K-NN:\n",
        "\n",
        "```\n",
        "Best parameters: {'regressor__n_neighbors': 10, 'regressor__weights': 'uniform'}\n",
        "MRRMSE en el conjunto de prueba: 1.0797109579201776\n",
        "```\n",
        "*Se muestran los resultados de esta forma por el alto costo computacional.*\n",
        "\n",
        "Los resultados muestran que el modelo KNN-Regressor, con los mejores parámetros identificados (`n_neighbors` = 10 y `weights` = 'uniform'), presenta un rendimiento moderado en el conjunto de prueba, con un MRRMSE de 1.08.\n",
        "\n",
        "**Interpretación:**\n",
        "\n",
        "1. **Número de Vecinos (`n_neighbors`)**: Con 10 vecinos, el modelo podría no estar capturando todas las variaciones en los datos. aumentar el numero de vecinos nos ayudaria a tener un mejor score aunque esto también puede incrementar el tiempo de cálculo y potencialmente llevar a un sobreajuste si se elige un número excesivamente alto.\n",
        "\n",
        "2. **Pesos Uniformes (`weights` = 'uniform')**: El uso de pesos uniformes implica que todos los vecinos tienen el mismo peso en las predicciones.\n",
        "\n",
        "3. **Capacidad de Generalización**: El MRRMSE relativamente alto sugiere que el modelo aún no está generalizando de manera óptima.\n",
        "\n",
        "En resumen, aunque los parámetros seleccionados han mejorado el rendimiento, el MRRMSE indica que el modelo aún puede ser optimizado. Considerar ajustes adicionales en la configuración del KNN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUdaVoJksSzF"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZLBgAAHmzuM",
        "outputId": "01c9bd0f-5d96-45b6-a3a2-87c0a46b3d50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nlinear = LinearRegression()\\n\\n# Configurar el pipeline con un escalador y el modelo de regresión lineal\\npipe = Pipeline([('scaler', StandardScaler()), ('lr', linear)])\\npipe.fit(X_train, y_train)\\n\\n# Predicciones\\ny_predtrain = pipe.predict(X_train)\\ny_pred = pipe.predict(X_test)\\n\\n# Calcular MRRMSE\\nmrrmse_train = MRRMSE(y_train, y_predtrain)\\nmrrmse = MRRMSE(y_test, y_pred)\\n\\n# Coeficientes e Intercepción\\ncoefficients = pipe.named_steps['lr'].coef_\\nintercept = pipe.named_steps['lr'].intercept_\\n\\n# Imprimir resultados\\nprint(f'MRRMSE en el conjunto de entrenamiento: {mrrmse_train}')\\nprint(f'Intercepción del modelo: {intercept}')\\n\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "linear = LinearRegression()\n",
        "\n",
        "# Configurar el pipeline con un escalador y el modelo de regresión lineal\n",
        "pipe = Pipeline([('scaler', StandardScaler()), ('lr', linear)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_predtrain = pipe.predict(X_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Calcular MRRMSE\n",
        "mrrmse_train = MRRMSE(y_train, y_predtrain)\n",
        "mrrmse = MRRMSE(y_test, y_pred)\n",
        "\n",
        "# Coeficientes e Intercepción\n",
        "coefficients = pipe.named_steps['lr'].coef_\n",
        "intercept = pipe.named_steps['lr'].intercept_\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f'MRRMSE en el conjunto de entrenamiento: {mrrmse_train}')\n",
        "print(f'Intercepción del modelo: {intercept}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz4M9FLBnY_t"
      },
      "source": [
        "## LOS RESULTADOS REGRESION LINEAL:\n",
        "\n",
        "```\n",
        "MRRMSE en el conjunto de entrenamiento: 0.9926474178039006\n",
        "Intercepción del modelo: [ 0.02240326  0.36188023  0.26452489 ...  0.17108057 -0.17544219\n",
        " -0.09517982]\n",
        "```\n",
        "*Se muestran los resultados de esta forma por el alto costo computacional.*\n",
        "\n",
        "\n",
        "Los resultados muestran que el modelo de regresión lineal tiene un **MRRMSE de 0.993** en el conjunto de entrenamiento, lo que indica un ajuste relativamente bueno a los datos de entrenamiento. Este valor es inferior a 1, sugiriendo que el modelo predice con una buena precisión.\n",
        "\n",
        "La **intercepción del modelo** muestra una variedad de valores, con algunos positivos y otros negativos, reflejando cómo el modelo ajusta las predicciones en función de las características de entrada.\n",
        "\n",
        "**Conclusión**: El modelo presenta un error de entrenamiento bajo, lo que es una señal positiva para el ajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5VyxdJwlHSy"
      },
      "source": [
        "# Comparación de Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vjZnOS8lC6k"
      },
      "source": [
        "## Evaluación de los Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MMjPAW3W1Vow"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jA6MV9Q1QqD",
        "outputId": "49b65365-3c52-4edc-ceb9-e06142545b83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\\n\\n# Realizar predicciones usando los modelos optimizados\\nknn_y_pred = grid_knr.predict(X_test)\\nlin_y_pred = pipe.predict(X_test)\\n\\n# Crear un diccionario con las métricas de evaluación para ambos modelos\\ndata = {\\n    'Modelo': ['K-NN', 'Linear Regression'],\\n    'MAPE': [\\n        mean_absolute_percentage_error(y_test, knn_y_pred),\\n        mean_absolute_percentage_error(y_test, lin_y_pred)\\n    ],\\n    'MAE': [\\n        mean_absolute_error(y_test, knn_y_pred),\\n        mean_absolute_error(y_test, lin_y_pred)\\n    ],\\n    'RMSE': [\\n        mean_squared_error(y_test, knn_y_pred, squared=False),  # RMSE = Raíz del MSE\\n        mean_squared_error(y_test, lin_y_pred, squared=False)\\n    ],\\n    'MSE': [\\n        mean_squared_error(y_test, knn_y_pred),\\n        mean_squared_error(y_test, lin_y_pred)\\n    ],\\n    'R²': [\\n        r2_score(y_test, knn_y_pred),\\n        r2_score(y_test, lin_y_pred)\\n    ]\\n}\\n\\n# Convertir el diccionario en un DataFrame de Pandas para una mejor visualización\\ndf = pd.DataFrame(data)\\nprint(df)\\n\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "# Realizar predicciones usando los modelos optimizados\n",
        "knn_y_pred = grid_knr.predict(X_test)\n",
        "lin_y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Crear un diccionario con las métricas de evaluación para ambos modelos\n",
        "data = {\n",
        "    'Modelo': ['K-NN', 'Linear Regression'],\n",
        "    'MAPE': [\n",
        "        mean_absolute_percentage_error(y_test, knn_y_pred),\n",
        "        mean_absolute_percentage_error(y_test, lin_y_pred)\n",
        "    ],\n",
        "    'MAE': [\n",
        "        mean_absolute_error(y_test, knn_y_pred),\n",
        "        mean_absolute_error(y_test, lin_y_pred)\n",
        "    ],\n",
        "    'RMSE': [\n",
        "        mean_squared_error(y_test, knn_y_pred, squared=False),  # RMSE = Raíz del MSE\n",
        "        mean_squared_error(y_test, lin_y_pred, squared=False)\n",
        "    ],\n",
        "    'MSE': [\n",
        "        mean_squared_error(y_test, knn_y_pred),\n",
        "        mean_squared_error(y_test, lin_y_pred)\n",
        "    ],\n",
        "    'R²': [\n",
        "        r2_score(y_test, knn_y_pred),\n",
        "        r2_score(y_test, lin_y_pred)\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convertir el diccionario en un DataFrame de Pandas para una mejor visualización\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMbXILjoGH3"
      },
      "source": [
        "## COMPARACIÓN DE MODELOS:\n",
        "\n",
        "```\n",
        "              Modelo       MAPE       MAE      RMSE       MSE        R²\n",
        "0               K-NN   8.585485  0.782599  1.544978  3.202212  0.213194\n",
        "1  Linear Regression  13.028350  0.770418  1.432576  2.730580  0.295072\n",
        "```\n",
        "*Se muestran los resultados de esta forma por el alto costo computacional.*\n",
        "\n",
        "\n",
        "Los resultados comparativos de los modelos muestran que el **modelo K-NN** tiene un **MAPE de 8.59**, un **MAE de 0.78**, un **RMSE de 1.54**, un **MSE de 3.20**, y un **R² de 0.21**. Estos valores indican que el modelo K-NN tiene una aproximacion relativamente baja en términos de precisión y capacidad de explicación de la variabilidad de los datos.\n",
        "\n",
        "Por otro lado, la **regresión lineal** muestra un **MAPE de 13.03**, un **MAE de 0.77**, un **RMSE de 1.43**, un **MSE de 2.73**, y un **R² de 0.30**. Aunque el MAPE es mayor comparado con el K-NN, la regresión lineal tiene un menor MAE, RMSE y MSE, lo que indica que tiene ajuste relativamente más preciso.\n",
        "\n",
        "**Conclusión**: Ambos modelos presentan tienes falencias en términos de ajuste y capacidad predictiva, pero la regresión lineal parece tener un desempeño superior en términos de precisión y capacidad de explicación de los datos comparado con el K-NN."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
